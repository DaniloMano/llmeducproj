# ğŸ§  Gemini Advanced RAG com Langflow
Este modelo implementa um fluxo de RAG AvanÃ§ado (GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o) usando Langflow, projetado para o Gemini responder perguntas com base exclusivamente em um documento institucional da UFRN. O sistema garante respostas precisas, controladas e verificÃ¡veis.

# âš™ï¸ Etapas do Processo
## ğŸ“¥ 1. Input do UsuÃ¡rio
O usuÃ¡rio insere uma pergunta no componente ChatInput.

A pergunta Ã© enviada para prÃ©-processamento e conversÃ£o em consulta vetorial.

## ğŸ§¹ 2. PrÃ©-processamento da Pergunta
Um Agent realiza ajustes na pergunta original para tornÃ¡-la mais adequada Ã  busca semÃ¢ntica.

Objetivo: evitar ambiguidade e garantir uma boa correspondÃªncia com os documentos vetorizados.

## ğŸ” 3. ConversÃ£o para Vetor de Consulta
Utiliza o Google Generative AI Embeddings para transformar a pergunta processada em um vetor semÃ¢ntico.

A conversÃ£o alimenta o mecanismo de busca no banco vetorial (Vector Store).

## ğŸ—‚ï¸ 4. Busca no Banco de Dados Vetorial
O componente Chroma DB Ã© usado para recuperar trechos do regulamento mais relevantes com base na similaridade vetorial.

Retorna os top-N resultados da pesquisa como context.

## ğŸ§½ 5. Filtragem dos Resultados
Um Prompt personalizado e um Agent refinam o conteÃºdo dos trechos retornados:

Seleciona apenas os trechos mais diretamente relacionados Ã  pergunta.

Remove conteÃºdos genÃ©ricos, duplicados ou que nÃ£o ajudam a responder.

## ğŸ¤– 6. Resposta da LLM Principal
A LLM recebe:

A pergunta original.

O contexto filtrado.

Gera uma resposta exclusivamente com base no documento, respeitando instruÃ§Ãµes especÃ­ficas como citar artigos e evitar suposiÃ§Ãµes.

## ğŸ’¬ 7. Entrega da Resposta ao UsuÃ¡rio
A resposta final Ã© enviada ao componente ChatOutput, onde o usuÃ¡rio vÃª o resultado processado.

## ğŸ§  CaracterÃ­sticas AvanÃ§adas
- ğŸ” Busca semÃ¢ntica vetorial: mais eficaz que busca por palavras-chave.

- ğŸ“‘ Filtragem contextual: evita que a LLM tenha acesso a informaÃ§Ãµes irrelevantes.

- ğŸ“˜ Conformidade do Documento: respostas sÃ£o sempre baseadas no documento.

- ğŸ”„ ReutilizaÃ§Ã£o e validaÃ§Ã£o em camadas: possÃ­vel integraÃ§Ã£o com revisores de resposta, validaÃ§Ã£o binÃ¡ria, entre outros.

## ğŸ› ï¸ Tecnologias e Componentes
Langflow

Google Generative AI Embeddings

Chroma Vector Store

Prompt customizado para filtragem e geraÃ§Ã£o

Gemini como LLM principal

Fluxo modular e expandÃ­vel

## ğŸ“Œ ObservaÃ§Ãµes
- O sistema pode receber outros documentos.
- Necessita-se de uma bateria de testes para validar esta modelo do Advnc RAG, assim como a engenharia de prompt (nos nodes de prompt, ou agent instructions e templates nos agentes de llm) deste modelo
- Se necessÃ¡rio, corrigir aspectos do modelo com base em ajustes com orientaÃ§Ã£o docente a fim de chegar aos resultados ou formataÃ§Ãµes esperados.