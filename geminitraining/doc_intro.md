# üí¨ Chatbot RAG com Gemini 2.0 Flash (Langflow + ChromaDB)

Este reposit√≥rio demonstra a cria√ß√£o de um **chatbot simples com RAG (Retrieval-Augmented Generation)** utilizando o modelo **Gemini 2.0 Flash**, atrav√©s do **Langflow**, com base em um documento acad√™mico da UFRN.

---

## üìö Contexto

A base de conhecimento usada neste projeto foi o documento:

> **`regulamento_dos_cursos_de_graduacao`**  
> Documento oficial da Universidade Federal do Rio Grande do Norte (UFRN), que trata das normas dos cursos regulares de gradua√ß√£o.

---

## ‚ñ∂Ô∏è Tutorial base

O projeto foi baseado no v√≠deo do canal *YAITEC Solutions*:
> [LANGFLOW ‚Äì Monte Seus Pr√≥prios Agentes de IA (No-Code) ‚Äì Vers√£o Atualizada](https://www.youtube.com/watch?v=7jVO3j-qE4w)

---

## üõ†Ô∏è Tecnologias e Ferramentas Utilizadas

- **Langflow**: interface visual para montar pipelines com LLMs e RAG.
- **LangChain**: biblioteca para orquestrar os componentes de IA.
- **Google Generative AI (Gemini 2.0 Flash)**: modelo usado para gera√ß√£o de respostas.
- **GoogleGenerativeAIEmbeddings**: embeddings gerados via LangChain (`langchain-google-genai`).
- **ChromaDB**: usado como vetor store para recupera√ß√£o de contexto relevante.
- **PDF Loader**: utilizado dentro do Langflow para carregar o conte√∫do do documento.

---

## üß© Estrutura L√≥gica do Projeto (via Langflow)

1. **Carregamento do Documento**  
   - O documento em PDF foi carregado com um n√≥ de `PDFLoader`.

2. **Gera√ß√£o de Embeddings**  
   - Embeddings gerados com o `GoogleGenerativeAIEmbeddings`.

3. **Armazenamento Vetorial**  
   - Armazenamento e busca feitos com o `Chroma Vector Store`.

4. **Agente Gemini**  
   - Utiliza√ß√£o do modelo `gemini-2.0-flash` atrav√©s do componente `Google Generative AI`.

5. **Prompt customizado**  
   - O chatbot foi instru√≠do a sempre consultar o documento `regulamento_dos_cursos_de_graduacao` para responder d√∫vidas com precis√£o.

---

## üß™ Resultados dos Testes

Apesar de uma certa **lat√™ncia nas respostas** (possivelmente relacionada ao Langflow ou √† simplicidade da estrutura montada), os testes apresentaram **respostas bastante precisas e contextualizadas** com base no conte√∫do do documento.

> ‚ö†Ô∏è *Nota: Caso a lentid√£o seja relacionada ao Langflow, uma arquitetura mais robusta ou otimiza√ß√£o do pipeline pode melhorar o tempo de resposta.*

---

## ‚úÖ Exemplos de Perguntas Testadas

- "Quantas vezes posso trancar uma disciplina?"
- "O que acontece se eu perder o prazo para matr√≠cula?"
- "Qual o tempo m√°ximo para concluir um curso de gradua√ß√£o?"

---
## Resultados Rasos

- Apesar do aumento da precis√£o, alucina√ß√£o ainda √© um problema.
- Engenharia de Prompt se mostrou eficaz para combater alucina√ß√£o.
- √â necess√°rio realizar restes com uma bateria de testes melhor para provar a efic√°cia da engenharia de prompt (e melhorar ela) como sendo mais vi√°vel que optar pelo uso de uma llm alternativa.

---
## üì¶ Requisitos

- Conta no [Google AI Studio](https://makersuite.google.com/app)
- Chave da API do Gemini ativada
- DataStax Langflow (nesse teste foi usado a vers√£o web)
